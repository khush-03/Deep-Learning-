{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162a11dd-d079-4ae0-9eee-d12b04b53bc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image Classification using CNN from Scratch\n",
    "In this notebook, we will build a Convolutional Neural Network (CNN) from scratch for image classification to predict whether an image is of a cat or a dog. We will use basic Python and numpy to achieve this without any high-level deep learning libraries like Keras or TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cd9c51-a352-48bb-af41-73332be2753f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming images are 100x100 RGB (3 channels)\n",
    "IMG_HEIGHT = 100\n",
    "IMG_WIDTH = 100\n",
    "IMG_CHANNELS = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3619b-e6e1-4c5a-acfc-900b523ac671",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "We define a Convolutional layer that applies filters to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d11bdae-31a0-4016-a91e-1f5f8cec9022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, num_filters, filter_size):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size, IMG_CHANNELS) / 9\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        h, w, _ = image.shape\n",
    "        new_h = h - self.filter_size + 1\n",
    "        new_w = w - self.filter_size + 1\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                region = image[i:i+self.filter_size, j:j+self.filter_size]\n",
    "                yield region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input = input\n",
    "        h, w, _ = input.shape\n",
    "        output = np.zeros((h - self.filter_size + 1, w - self.filter_size + 1, self.num_filters))\n",
    "        \n",
    "        for region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.sum(region * self.filters, axis=(1, 2, 3))\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, d_L_d_out, learn_rate):\n",
    "        d_L_d_filters = np.zeros(self.filters.shape)\n",
    "        for region, i, j in self.iterate_regions(self.last_input):\n",
    "            for f in range(self.num_filters):\n",
    "                d_L_d_filters[f] += d_L_d_out[i, j, f] * region\n",
    "\n",
    "        self.filters -= learn_rate * d_L_d_filters\n",
    "        return None  # Convolutional layers typically return None in backward pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ebcb0-e39c-4dd4-878f-136008e9a3f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Max Pooling Layer\n",
    "We define a MaxPooling layer to down-sample the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae21768c-8e28-4588-a565-792fe33895d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MaxPooling2D:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def iterate_regions(self, image):\n",
    "        h, w, num_filters = image.shape\n",
    "        new_h = h // self.pool_size\n",
    "        new_w = w // self.pool_size\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                region = image[(i*self.pool_size):(i*self.pool_size+self.pool_size),\n",
    "                               (j*self.pool_size):(j*self.pool_size+self.pool_size)]\n",
    "                yield region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input = input\n",
    "        h, w, num_filters = input.shape\n",
    "        output = np.zeros((h // self.pool_size, w // self.pool_size, num_filters))\n",
    "        \n",
    "        for region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(region, axis=(0, 1))\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, d_L_d_out):\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "        \n",
    "        for region, i, j in self.iterate_regions(self.last_input):\n",
    "            h, w, f = region.shape\n",
    "            amax = np.amax(region, axis=(0, 1))\n",
    "            \n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        if region[i2, j2, f2] == amax[f2]:\n",
    "                            d_L_d_input[i*self.pool_size + i2, j*self.pool_size + j2, f2] = d_L_d_out[i, j, f2]\n",
    "        \n",
    "        return d_L_d_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d526b60-ea44-4138-82a0-8461b5b19681",
   "metadata": {},
   "source": [
    "## Dense Layer\n",
    "We define a Dense (fully connected) layer to process the flattened input from previous layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8ae7eca-a450-4713-aca4-32be71f553d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, input_len, nodes):\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.biases = np.zeros(nodes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input_shape = input.shape\n",
    "        input = input.flatten()\n",
    "        self.last_input = input\n",
    "        input_len, nodes = self.weights.shape\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        self.last_totals = totals\n",
    "        return totals\n",
    "\n",
    "    def backward(self, d_L_d_out, learn_rate):\n",
    "        d_L_d_t = d_L_d_out\n",
    "        \n",
    "        d_t_d_w = self.last_input\n",
    "        d_t_d_b = 1\n",
    "        d_t_d_inputs = self.weights\n",
    "        \n",
    "        d_L_d_w = np.dot(d_t_d_w[:, np.newaxis], d_L_d_t[np.newaxis, :])\n",
    "        d_L_d_b = d_L_d_t * d_t_d_b\n",
    "        d_L_d_inputs = np.dot(d_t_d_inputs, d_L_d_t)\n",
    "        \n",
    "        self.weights -= learn_rate * d_L_d_w\n",
    "        self.biases -= learn_rate * d_L_d_b\n",
    "        \n",
    "        return d_L_d_inputs.reshape(self.last_input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96ebae-59ff-476d-b2c1-795e67b22ebe",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "We define helper functions for softmax activation, cross-entropy loss, and image preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1910c062-53a8-4da0-97fa-a0306bf8df9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / exp_x.sum(axis=0)\n",
    "\n",
    "def cross_entropy_loss(output, y):\n",
    "    return -np.log(output[int(y)])  # Ensure y is an integer\n",
    "\n",
    "def preprocess_image(image_array):\n",
    "    return image_array.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2079db5-d0c7-4e1f-a5d6-8f73d5bb86e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Forward and Train Functions\n",
    "We define functions to perform the forward pass and training (including backpropagation) of the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6160537d-c392-4744-8604-ba9a3f0c1f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(image, label):\n",
    "    out = conv.forward((image / 255) - 0.5)\n",
    "    out = pool.forward(out)\n",
    "    out = softmax(dense.forward(out))\n",
    "    \n",
    "    loss = cross_entropy_loss(out, label)\n",
    "    acc = 1 if np.argmax(out) == int(label) else 0  # Ensure label is an integer\n",
    "    \n",
    "    return out, loss, acc\n",
    "\n",
    "def train(im, label, lr=.005):\n",
    "    out, loss, acc = forward(im, label)\n",
    "    \n",
    "    grad = np.zeros(2)  # Since we have 2 classes (cat, dog)\n",
    "    grad[int(label)] = -1 / out[int(label)]  # Ensure label is an integer\n",
    "    \n",
    "    grad = dense.backward(grad, lr)\n",
    "    grad = pool.backward(grad)\n",
    "    grad = conv.backward(grad, lr)\n",
    "    \n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1786ac-350b-44c8-9737-b44918e79ebe",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "Load the dataset from CSV files and preprocess it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90918c6b-6325-4836-86e8-8838167df4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "X_train = np.loadtxt(r'C:\\Users\\khush\\Downloads\\Image Classification using CNN Keras Dataset Compress\\compress\\input_compress.csv', delimiter=',')\n",
    "Y_train = np.loadtxt(r'C:\\Users\\khush\\Downloads\\Image Classification using CNN Keras Dataset Compress\\compress\\labels_compress.csv', delimiter=',')\n",
    "X_test = np.loadtxt(r'C:\\Users\\khush\\Downloads\\Image Classification using CNN Keras Dataset Compress\\compress\\input_test_compress.csv', delimiter=',')\n",
    "Y_test = np.loadtxt(r'C:\\Users\\khush\\Downloads\\Image Classification using CNN Keras Dataset Compress\\compress\\labels_test_compress.csv', delimiter=',')\n",
    "    \n",
    "# Reshape dataset\n",
    "X_train = np.array([preprocess_image(x) for x in X_train])\n",
    "X_test = np.array([preprocess_image(x) for x in X_test])\n",
    "\n",
    "# Convert labels to integers\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a8c792-403b-4f16-b92d-f833cff7ef42",
   "metadata": {},
   "source": [
    "## Initialize Layers\n",
    "Initialize the CNN layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5e6b5c-09b0-4a4e-ac31-315240038edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize layers\n",
    "conv = Conv2D(8, 3)\n",
    "pool = MaxPooling2D(2)\n",
    "dense = Dense((IMG_HEIGHT - 2) // 2 * (IMG_WIDTH - 2) // 2 * 8, 2)  # Adjust based on input image size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f66982-ba29-4591-9faa-aee6c0608fb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Loop\n",
    "Train the CNN using the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b4a3843-72d3-4b28-8c25-657f0674f994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khush\\AppData\\Local\\Temp\\ipykernel_21228\\2141419804.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log(output[int(y)])  # Ensure y is an integer\n",
      "C:\\Users\\khush\\AppData\\Local\\Temp\\ipykernel_21228\\2406924954.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  grad[int(label)] = -1 / out[int(label)]  # Ensure label is an integer\n",
      "C:\\Users\\khush\\AppData\\Local\\Temp\\ipykernel_21228\\79126733.py:30: RuntimeWarning: invalid value encountered in add\n",
      "  d_L_d_filters[f] += d_L_d_out[i, j, f] * region\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: nan, Accuracy: 0.507\n",
      "--- Epoch 2 ---\n",
      "Epoch 2, Loss: nan, Accuracy: 0.500\n",
      "--- Epoch 3 ---\n",
      "Epoch 3, Loss: nan, Accuracy: 0.500\n",
      "Test Loss: nan, Test Accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "learning_rate = 0.005\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'--- Epoch {epoch + 1} ---')\n",
    "    permutation = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[permutation]\n",
    "    Y_train = Y_train[permutation]\n",
    "    \n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    for i, (im, label) in enumerate(zip(X_train, Y_train)):\n",
    "        l, acc = train(im, label, lr=learning_rate)\n",
    "        loss += l\n",
    "        num_correct += acc\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss:.3f}, Accuracy: {num_correct / len(X_train):.3f}')\n",
    "\n",
    "# Evaluation on test data\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "\n",
    "for im, label in zip(X_test, Y_test):\n",
    "    _, l, acc = forward(im, label)\n",
    "    test_loss += l\n",
    "    test_correct += acc\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_correct / len(X_test):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569b3ef-2f15-48e0-9154-360d90466722",
   "metadata": {},
   "source": [
    "This code includes the essential components: convolutional layer (Conv2D), max-pooling layer (MaxPooling2D), and dense layer (Dense). It also contains a simple train function that includes forward and backward propagation to update the weights.\n",
    "\n",
    "This implementation does not include certain advanced features and optimizations found in libraries like Keras or PyTorch, but it provides a fundamental understanding of how these layers and training processes work under the hood\n",
    "\n",
    "Note: This code provides a very basic implementation and lacks many features of robust deep learning frameworks. For practical purposes, using libraries like TensorFlow/Keras or PyTorch is recommended.\n",
    "\n",
    "Done by khush jay brahmbhatt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bfbb45-f779-47cf-8130-fa8f72096721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
